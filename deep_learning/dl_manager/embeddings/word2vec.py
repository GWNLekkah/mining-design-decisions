import pathlib

from gensim.models import Word2Vec as GensimWord2Vec

from .embedding_generator import AbstractEmbeddingGenerator, EmbeddingGeneratorParam


class Word2VecGenerator(AbstractEmbeddingGenerator):

    def generate_embedding(self, issues: list[str], path: pathlib.Path):
        min_count = self.params.get('min-count', 0)
        vector_size = self.params['vector-size']
        model = GensimWord2Vec(issues, min_count=min_count, vector_size=vector_size)
        model.wv.save_word2vec_format(path, binary=True)

    @staticmethod
    def get_params() -> dict[str, EmbeddingGeneratorParam]:
        return super(Word2VecGenerator, Word2VecGenerator).get_params() | {
            'vector-size': EmbeddingGeneratorParam(
                description='Size of the vectors generated by Doc2Vec',
                data_type='int',
                minimum=2,
                maximum=10000
            ),
            'min-count': EmbeddingGeneratorParam(
                description='Minimum amount of occurrences for a word to be included',
                data_type='int',
                minimum=0,
                maximum=10000
            )
        }
