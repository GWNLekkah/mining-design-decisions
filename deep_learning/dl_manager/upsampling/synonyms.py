import copy
import json
import random

import numpy
from gensim import models

from .base import AbstractUpSampler, UpsamplerHyperParam
from ..config import conf
from ..feature_generators import generators, FeatureEncoding
from .. import data_manager_bootstrap


class SynonymUpSampler(AbstractUpSampler):

    def upsample(self, indices, targets, labels, keys, *features):
        self._check_generators()
        self._check_feature_encoding()
        return super().upsample(indices, targets, labels, keys, *features)

    def upsample_class(self, indices, target, labels, keys, *features):
        # We need a number of things:
        # 1) the word-embedding used to generate the word2vec features
        # 2) the BowFreq index mapping
        # 3) the BOWNorm Index mapping
        # 4) The Word2Vec index mapping
        # 5) a word embedding for synonym detection.
        # 6) original issue text
        #
        # 1-4 are generator settings, 5 is a hyper-param for the up-sampler.
        # 6 is generated by the generator
        with open(data_manager_bootstrap.get_raw_text_file_name()) as file:
            original_issue_text = json.load(file)
        generator_settings = []
        for filename in conf.get('system.storage.generators'):
            with open(filename) as file:
                data = json.load(file)
            match data['generator']:
                case 'Word2Vec1D':
                    generator_settings.append(
                        (
                            data['generator'],
                            (
                                data['settings']['word-to-index-mapping'],
                                models.KeyedVectors.load_word2vec_format(
                                    data['settings']['model'], binary=data['settings']['model-binary']
                                )
                            )
                        )
                    )
                case 'BOWFrequency' | 'BOWNormalized':
                    generator_settings.append(
                        (
                            data['generator'],
                            data['settings']['word-to-index-mapping']
                        )
                    )
                case _ as x:
                    raise ValueError(f'Unsupported feature generator: {x}')
        synonym_wv = models.KeyedVectors.load_word2vec_format(
            self.hyper_params['word-embedding'],
            binary=self.hyper_params.get('word-embedding-is-binary', 'True').lower() == 'true'
        )
        min_replace = int(self.hyper_params.get('min-replace', '10'))
        max_replace = int(self.hyper_params.get('max-replace', '20'))
        if min_replace > max_replace:
            raise ValueError('min-replace must be <= max-replace')
        n_synonyms = int(self.hyper_params.get('n-synonyms', '5'))
        failures = 0
        new_features = []
        for i in random.choices(indices, k=target - len(indices)):
            key = keys[i]
            text = original_issue_text[key]
            original_features = [copy.deepcopy(f[i]) for f in features]
            high = min(max_replace, len(text) // 4)
            if min_replace > high:
                low = high // 2
            else:
                low = min_replace
            replace_indices = random.sample(
                range(0, len(text)),
                k=random.randint(low, high)
            )
            for index in replace_indices:
                synonyms = synonym_wv.most_similar(text[index], topn=n_synonyms)
                candidates = [s
                              for s in synonyms
                              if self._is_valid_candidate(s, generator_settings)]
                if not candidates:
                    failures += 1
                new_word = random.choice(candidates)
                self._update_features(index,
                                      text[index],
                                      new_word,
                                      generator_settings,
                                      original_features)
            new_features.append(original_features)
        print(f'{failures} encountered during synonym replacement')
        return [numpy.asarray(x) for x in zip(*new_features)]

    @staticmethod
    def _is_valid_candidate(s, all_settings):
        for g, settings in zip(all_settings):
            match g:
                case 'BOWNormalized' | 'BOWFrequency':
                    return s in settings
                case 'Word2Vec1D':
                    return s in settings[0]
                case _:
                    raise ValueError(f'Unhandled generator: {g}')

    @staticmethod
    def _update_features(index, old_word, new_word, generator_settings, features):
        for f, (g, settings) in zip(features, generator_settings):
            match g:
                case 'BOWNormalized':
                    f[settings[old_word]] -= 1
                    f[settings[new_word]] += 1
                case 'BOWNormalized':
                    n = sum(f)
                    f[settings[old_word]] -= 1/n
                    f[settings[new_word]] += 1/n
                case 'Word2Vec1D':
                    f[index] = generator_settings[0][new_word]
                case _:
                    raise ValueError(f'Unhandled generator: {g}')

    @staticmethod
    def get_hyper_params():
        return super().get_hyper_params() | {
            'word-embedding': UpsamplerHyperParam(
                description='Path to the word embedding file to use to determine synonyms',
                data_type='str',
                default=''
            ),
            'word-embedding-is-binary': UpsamplerHyperParam(
                description='True is word embedding file is binary',
                data_type='bool',
                default='True'
            ),
            'min-replace': UpsamplerHyperParam(
                description='Minimum amount of words to replace per issue',
                data_type='int',
                default=10
            ),
            'max-replace': UpsamplerHyperParam(
                description='Maximum amount of words to replace per issue',
                data_type='int',
                default=20
            ),
            'n-synonyms': UpsamplerHyperParam(
                description='Amount of synonyms to consider per replacement',
                data_type='int',
                default=5
            )
        }

    def _check_feature_encoding(self):
        encodings = [
            generators[i].feature_encoding()
            for i in conf.get('run.input-mode')
        ]
        if any(e != FeatureEncoding.Numerical for e in encodings):
            raise ValueError('Can only apply SMOTE when using purely numerical features')

    def _check_generators(self):
        for i in conf.get('run.input-mode'):
            if i not in {'Word2Vec1D', 'BOWFrequency', 'BOWNormalized'}:
                raise ValueError(f'Unsupported feature generator for {self.__class__.__name__}: {i}')
